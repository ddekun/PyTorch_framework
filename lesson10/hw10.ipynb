{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXAK7zcIcGdzdvukxuEVfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddekun/PyTorch_framework/blob/lesson10/lesson10/hw10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Фреймворк PyTorch для разработки искусственных нейронных сетей"
      ],
      "metadata": {
        "id": "HqLZn3s5HtVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Урок 10. Распознавание лиц и эмоций"
      ],
      "metadata": {
        "id": "smj32bAoHv7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание по итогам курса:\n",
        "(упрощенное/для тех, у кого нет вебкамеры)\n",
        "\n",
        "Нужно написать приложение, которое будет получать на вход изображение.\n",
        "В процессе определять, что перед камерой находится человек, задетектировав его лицо на кадре.\n",
        "На изображении человек показывает жесты руками, а алгоритм должен считать их и классифицировать.\n",
        "(более сложное)\n",
        "\n",
        "Нужно написать приложение, которое будет считывать и выводить кадры с веб-камеры.\n",
        "В процессе считывания определять что перед камерой находится человек, задетектировав его лицо на кадре.\n",
        "Человек показывает жесты руками, а алгоритм должен считать их и классифицировать.\n",
        "Для распознавания жестов, вам надо будет скачать датасет https://www.kaggle.com/gti-upm/leapgestrecog, разработать модель для обучения и обучить эту модель.\n",
        "Как работать с веб-камерой на google colab https://stackoverflow.com/questions/54389727/opening-web-camera-in-google-colab\n",
        "У кого нет возможности работать через каггл (нет верификации), то можете данные взять по ссылке: https://disk.yandex.ru/d/R2PGlaXDf6_HzQ\n",
        "\n",
        "Данная промежуточная аттестация оценивается по системе \"зачет\" / \"не зачет\"\n",
        "Зачет\" ставится, если слушатель успешно выполнил задание 1 или 2 задания\n",
        "\"Незачет\"\" ставится, если слушатель не выплнил 0 заданий\n",
        "\n",
        "Критерии оценивания:\n",
        "Слушатель написал приложение, которое будет получать на вход изображение\n",
        "Слушатель написать приложение, которое будет считывать и выводить кадры с веб-камеры"
      ],
      "metadata": {
        "id": "IjTv0Y6AHx7l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JylCCW6rHq3N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as tt\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH4pPLjVH34c",
        "outputId": "7158dd0a-1097-42cf-c473-02096d64ecdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = ['01_palm', '02_l','03_fist','04_fist_moved','05_thumb','06_index','07_ok','08_palm_moved','09_c','10_down']"
      ],
      "metadata": {
        "id": "VNev4u-gIA4H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = glob.glob('./leapGestRecog/**/**/**/*.png')\n",
        "\n",
        "label = [int(os.path.basename(i).split('_')[2])-1 for i in images]"
      ],
      "metadata": {
        "id": "JHIj1G-vIDDN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transformer = transforms.Compose([\n",
        "                    transforms.Resize((48, 128)),  # пропорциональное изменение от первоначального размера 240х640\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor()])\n",
        "\n",
        "test_transformer = transforms.Compose([\n",
        "                   transforms.Resize((48, 128)),\n",
        "                   transforms.Grayscale(num_output_channels=1),\n",
        "                   transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "G1vonJh-IFVd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images, label, test_size = 0.3, random_state=42)"
      ],
      "metadata": {
        "id": "ZUSY6LgzIHR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeapGestRecogDataset(Dataset):\n",
        "    def __init__(self, filenames, labels, transform):\n",
        "        self.filenames = filenames\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.filenames[idx])\n",
        "        image = self.transform(image)\n",
        "        return image, self.labels[idx]"
      ],
      "metadata": {
        "id": "WSxuZpurJ0tc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LeapGestRecogDataset(X_train, y_train, train_transformer)\n",
        "test_dataset = LeapGestRecogDataset(X_test, y_test, test_transformer)"
      ],
      "metadata": {
        "id": "kn3uuNa0J5CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "lr = 0.01\n",
        "train_dl = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "test_dl = DataLoader(test_dataset, batch_size)"
      ],
      "metadata": {
        "id": "JwKILXbtJ9Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_dl)\n",
        "\n",
        "img, labels = data_iter.next()\n",
        "\n",
        "plt.figure(figsize=(14, 21))\n",
        "for i in range(batch_size):\n",
        "    ax = plt.subplot(9, 3, i+1)\n",
        "    plt.imshow(img[i, 0, :, :], cmap='gray')\n",
        "    plt.title(f'{CATEGORIES[int(labels[i])][3:]}')\n",
        "    if i > 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "Y_B-6TocKAT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.3)\n",
        "        self.fc1 = nn.Linear(32*22*62, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "vCpUmowYKFc4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "xl3FVssUKIY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "tQiRPyOIKM7A"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, epochs):\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_acc = []\n",
        "    epoch_val_losses = []\n",
        "    epoch_val_acc = []\n",
        "    bundle = 20\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        cum_loss = []\n",
        "        cum_acc = []\n",
        "\n",
        "        time1 = time.time()\n",
        "        model.train()\n",
        "        for i, data in enumerate(train_dl, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            cum_loss.append(loss.item())\n",
        "\n",
        "            total = labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct = (predicted == labels).sum().item()\n",
        "            cum_acc.append(correct / total)\n",
        "\n",
        "        time2 = time.time()\n",
        "        epoch_losses.append(np.mean(cum_loss))\n",
        "        epoch_acc.append(np.mean(cum_acc))\n",
        "\n",
        "        cum_loss = []\n",
        "        cum_acc = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            running_val_loss = 0.0\n",
        "            for i, data in enumerate(test_dl, 0):\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item()\n",
        "                cum_loss.append(loss.item())\n",
        "\n",
        "                total = labels.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct = (predicted == labels).sum().item()\n",
        "                cum_acc.append(correct / total)\n",
        "\n",
        "        epoch_val_losses.append(np.mean(cum_loss))\n",
        "        epoch_val_acc.append(np.mean(cum_acc))\n",
        "        print(f'Epochs: {epoch+1}   loss: {epoch_losses[-1]:.5f}   '\n",
        "              f'accuracy: {epoch_acc[-1]*100:.3f}%   '\n",
        "              f'loss_val: {epoch_val_losses[-1]:.5f}   '\n",
        "              f'accuracy_val: {epoch_val_acc[-1]*100:.3f}%   '\n",
        "              f'time = {time2-time1:.2f} s')\n",
        "\n",
        "    return {'epoch_losses': epoch_losses,\n",
        "            'epoch_val_losses': epoch_val_losses,\n",
        "            'epoch_acc': epoch_acc,\n",
        "            'epoch_val_acc': epoch_val_acc}"
      ],
      "metadata": {
        "id": "2pROc1VVKQ61"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(model, epochs)"
      ],
      "metadata": {
        "id": "BhAYrNw9KVWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), './leapGestRecog/gesture_recognition')"
      ],
      "metadata": {
        "id": "Y57_6xcFKYB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)\n",
        "net.load_state_dict(torch.load('./leapGestRecog/gesture_recognition', map_location=torch.device('cpu')))\n",
        "net.eval()"
      ],
      "metadata": {
        "id": "dV9hWXj4Ka4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(test_dl)\n",
        "\n",
        "img, labels = data_iter.next()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    inputs = img.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    total = labels.size(0)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    print(f'Correct: {correct} / {batch_size}')\n",
        "\n",
        "plt.figure(figsize=(14, 21))\n",
        "for i in range(batch_size):\n",
        "    ax = plt.subplot(9, 3, i+1)\n",
        "\n",
        "    plt.imshow(img[i, 0, :, :], cmap='gray')\n",
        "    if int(labels[i]) == int(predicted[i]):\n",
        "        plt.title(f'{CATEGORIES[int(labels[i])][3:]} / {CATEGORIES[int(predicted[i])][3:]}')\n",
        "    else:\n",
        "        plt.title(f'Error: {CATEGORIES[int(labels[i])][3:]} / {CATEGORIES[int(predicted[i])][3:]}')\n",
        "    plt.axis('off')\n",
        "    if i > 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "zyLMvT3KKeWH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}